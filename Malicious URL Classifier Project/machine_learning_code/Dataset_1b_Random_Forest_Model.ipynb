{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b756bae2",
   "metadata": {},
   "source": [
    "This notebook will: \n",
    "\n",
    "1. Drop the 'content' column for dataset 1.\n",
    "2. Engineer other features (url profanity score, top level domain encodings)\n",
    "3. Train different classification models: decision tree, random forest, gradient boosting, logistic regression\n",
    "4. Save the best model to disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d36b1148",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hatzi\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Sun Sep 09 11:40:11 2021\n",
    "    Build the model by following this notebook:\n",
    "@author: hatzi\n",
    "\"\"\"\n",
    "\n",
    "import nltk\n",
    "import string\n",
    "import re\n",
    "import sklearn\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, OrdinalEncoder\n",
    "from sklearn.cluster import MiniBatchKMeans\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from scipy import stats\n",
    "import nltk \n",
    "nltk.download('stopwords') #<---uncomment if you haven't downloaded the stopwords library\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "# Set working directory \n",
    "folder = r'C:\\Users\\hatzi\\Documents\\SUTD\\Systems Security Project\\Datasets\\Dataset of Malicious and Benign Webpages'\n",
    "os.chdir(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f84456c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url', 'url_len', 'ip_add', 'geo_loc', 'tld', 'who_is', 'https',\n",
       "       'js_len', 'js_obf_len', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load training dataset. Will take some time as dataset is 2GB\n",
    "df_train = pd.read_csv('Webpages_Classification_train_data.csv')\n",
    "\n",
    "# Drop content column as there is a seperate NLP model for it\n",
    "df_train = df_train.drop(['Unnamed: 0', 'content'], axis=1)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "65f8bc06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://members.tripod.com/russiastation/</td>\n",
       "      <td>40</td>\n",
       "      <td>42.77.221.155</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://www.ddj.com/cpp/184403822</td>\n",
       "      <td>32</td>\n",
       "      <td>3.211.202.180</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.naef-usa.com/</td>\n",
       "      <td>24</td>\n",
       "      <td>24.232.54.41</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.ff-b2b.de/</td>\n",
       "      <td>21</td>\n",
       "      <td>147.22.38.45</td>\n",
       "      <td>United States</td>\n",
       "      <td>de</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>720.0</td>\n",
       "      <td>532.8</td>\n",
       "      <td>bad</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://us.imdb.com/title/tt0176269/</td>\n",
       "      <td>35</td>\n",
       "      <td>205.30.239.85</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>46.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        url  url_len         ip_add  \\\n",
       "0  http://members.tripod.com/russiastation/       40  42.77.221.155   \n",
       "1          http://www.ddj.com/cpp/184403822       32  3.211.202.180   \n",
       "2                  http://www.naef-usa.com/       24   24.232.54.41   \n",
       "3                     http://www.ff-b2b.de/       21   147.22.38.45   \n",
       "4       http://us.imdb.com/title/tt0176269/       35  205.30.239.85   \n",
       "\n",
       "         geo_loc  tld      who_is https  js_len  js_obf_len label  \n",
       "0         Taiwan  com    complete   yes    58.0         0.0  good  \n",
       "1  United States  com    complete   yes    52.5         0.0  good  \n",
       "2      Argentina  com    complete   yes   103.5         0.0  good  \n",
       "3  United States   de  incomplete    no   720.0       532.8   bad  \n",
       "4  United States  com    complete   yes    46.5         0.0  good  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d9ed9994",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391034</th>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "      <td>624</td>\n",
       "      <td>93.69.163.42</td>\n",
       "      <td>Italy</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677514</th>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "      <td>628</td>\n",
       "      <td>186.24.149.197</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>no</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340683</th>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "      <td>644</td>\n",
       "      <td>54.75.74.161</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300502</th>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "      <td>648</td>\n",
       "      <td>39.208.168.21</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>78.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235778</th>\n",
       "      <td>http://pqasb.pqarchiver.com/sptimes/main/doc/0...</td>\n",
       "      <td>721</td>\n",
       "      <td>151.133.89.114</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>no</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  url_len  \\\n",
       "391034  http://www.drugdigest.org/wps/portal/!ut/p/c0/...      624   \n",
       "677514  http://www.drugdigest.org/wps/portal/!ut/p/c0/...      628   \n",
       "340683  http://www.drugdigest.org/wps/portal/!ut/p/c0/...      644   \n",
       "300502  http://www.drugdigest.org/wps/portal/!ut/p/c0/...      648   \n",
       "235778  http://pqasb.pqarchiver.com/sptimes/main/doc/0...      721   \n",
       "\n",
       "                ip_add         geo_loc  tld    who_is https  js_len  \\\n",
       "391034    93.69.163.42           Italy  org  complete   yes     0.0   \n",
       "677514  186.24.149.197       Venezuela  org  complete    no   101.0   \n",
       "340683    54.75.74.161         Ireland  org  complete   yes    89.0   \n",
       "300502   39.208.168.21       Indonesia  org  complete   yes    78.5   \n",
       "235778  151.133.89.114  United Kingdom  com  complete    no   102.0   \n",
       "\n",
       "        js_obf_len label  \n",
       "391034         0.0  good  \n",
       "677514         0.0  good  \n",
       "340683         0.0  good  \n",
       "300502         0.0  good  \n",
       "235778         0.0  good  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sort_values(by=['url_len']).tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87066768",
   "metadata": {},
   "source": [
    "#### Engineer url based features\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f40e9d9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>original_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>members tripod    russiastation</td>\n",
       "      <td>40</td>\n",
       "      <td>42.77.221.155</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://members.tripod.com/russiastation/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ddj    cpp 184403822</td>\n",
       "      <td>32</td>\n",
       "      <td>3.211.202.180</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.ddj.com/cpp/184403822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naef-usa</td>\n",
       "      <td>24</td>\n",
       "      <td>24.232.54.41</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.naef-usa.com/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ff-b2b</td>\n",
       "      <td>21</td>\n",
       "      <td>147.22.38.45</td>\n",
       "      <td>United States</td>\n",
       "      <td>de</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>720.0</td>\n",
       "      <td>532.8</td>\n",
       "      <td>bad</td>\n",
       "      <td>http://www.ff-b2b.de/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us imdb    title tt0176269</td>\n",
       "      <td>35</td>\n",
       "      <td>205.30.239.85</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>46.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://us.imdb.com/title/tt0176269/</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   url  url_len         ip_add        geo_loc  \\\n",
       "0  members tripod    russiastation           40  42.77.221.155         Taiwan   \n",
       "1              ddj    cpp 184403822          32  3.211.202.180  United States   \n",
       "2                      naef-usa              24   24.232.54.41      Argentina   \n",
       "3                        ff-b2b              21   147.22.38.45  United States   \n",
       "4       us imdb    title tt0176269           35  205.30.239.85  United States   \n",
       "\n",
       "   tld      who_is https  js_len  js_obf_len label  \\\n",
       "0  com    complete   yes    58.0         0.0  good   \n",
       "1  com    complete   yes    52.5         0.0  good   \n",
       "2  com    complete   yes   103.5         0.0  good   \n",
       "3   de  incomplete    no   720.0       532.8   bad   \n",
       "4  com    complete   yes    46.5         0.0  good   \n",
       "\n",
       "                               original_url  \n",
       "0  http://members.tripod.com/russiastation/  \n",
       "1          http://www.ddj.com/cpp/184403822  \n",
       "2                  http://www.naef-usa.com/  \n",
       "3                     http://www.ff-b2b.de/  \n",
       "4       http://us.imdb.com/title/tt0176269/  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from urllib.parse import urlparse\n",
    "from tld import get_tld\n",
    "\n",
    "# Function for cleaning the URL text before calling the profanity check \n",
    "def clean_url(url):\n",
    "    url_text=\"\"\n",
    "    try:\n",
    "        domain = get_tld(url, as_object=True)\n",
    "        domain = get_tld(url, as_object=True)\n",
    "        url_parsed = urlparse(url)\n",
    "        url_text= url_parsed.netloc.replace(domain.tld,\" \").replace('www',' ') +\" \"+ url_parsed.path+\" \"+url_parsed.params+\" \"+url_parsed.query+\" \"+url_parsed.fragment\n",
    "        url_text = url_text.translate(str.maketrans({'?':' ','\\\\':' ','.':' ',';':' ','/':' ','\\'':' '}))\n",
    "        url_text.strip(' ')\n",
    "        url_text.lower()\n",
    "    except:\n",
    "        url_text = url_text.translate(str.maketrans({'?':' ','\\\\':' ','.':' ',';':' ','/':' ','\\'':' '}))\n",
    "        url_text.strip(' ')\n",
    "    return url_text\n",
    "\n",
    "df_train['original_url'] = df_train['url']\n",
    "df_train['url'] = df_train['url'].map(clean_url)\n",
    "\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36c79c1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>original_url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>391034</th>\n",
       "      <td>drugdigest    wps portal !ut p c0 dy5ndoiwei...</td>\n",
       "      <td>624</td>\n",
       "      <td>93.69.163.42</td>\n",
       "      <td>Italy</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>677514</th>\n",
       "      <td>drugdigest    wps portal !ut p c0 dy5ndoiwei...</td>\n",
       "      <td>628</td>\n",
       "      <td>186.24.149.197</td>\n",
       "      <td>Venezuela</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>no</td>\n",
       "      <td>101.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>340683</th>\n",
       "      <td>drugdigest    wps portal !ut p c0 dy5bdoiwee...</td>\n",
       "      <td>644</td>\n",
       "      <td>54.75.74.161</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300502</th>\n",
       "      <td>drugdigest    wps portal !ut p c0 dy7bdoiwdi...</td>\n",
       "      <td>648</td>\n",
       "      <td>39.208.168.21</td>\n",
       "      <td>Indonesia</td>\n",
       "      <td>org</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>78.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.drugdigest.org/wps/portal/!ut/p/c0/...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235778</th>\n",
       "      <td>pqasb pqarchiver    sptimes main doc 000000057...</td>\n",
       "      <td>721</td>\n",
       "      <td>151.133.89.114</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>no</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://pqasb.pqarchiver.com/sptimes/main/doc/0...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      url  url_len  \\\n",
       "391034    drugdigest    wps portal !ut p c0 dy5ndoiwei...      624   \n",
       "677514    drugdigest    wps portal !ut p c0 dy5ndoiwei...      628   \n",
       "340683    drugdigest    wps portal !ut p c0 dy5bdoiwee...      644   \n",
       "300502    drugdigest    wps portal !ut p c0 dy7bdoiwdi...      648   \n",
       "235778  pqasb pqarchiver    sptimes main doc 000000057...      721   \n",
       "\n",
       "                ip_add         geo_loc  tld    who_is https  js_len  \\\n",
       "391034    93.69.163.42           Italy  org  complete   yes     0.0   \n",
       "677514  186.24.149.197       Venezuela  org  complete    no   101.0   \n",
       "340683    54.75.74.161         Ireland  org  complete   yes    89.0   \n",
       "300502   39.208.168.21       Indonesia  org  complete   yes    78.5   \n",
       "235778  151.133.89.114  United Kingdom  com  complete    no   102.0   \n",
       "\n",
       "        js_obf_len label                                       original_url  \n",
       "391034         0.0  good  http://www.drugdigest.org/wps/portal/!ut/p/c0/...  \n",
       "677514         0.0  good  http://www.drugdigest.org/wps/portal/!ut/p/c0/...  \n",
       "340683         0.0  good  http://www.drugdigest.org/wps/portal/!ut/p/c0/...  \n",
       "300502         0.0  good  http://www.drugdigest.org/wps/portal/!ut/p/c0/...  \n",
       "235778         0.0  good  http://pqasb.pqarchiver.com/sptimes/main/doc/0...  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.sort_values(by=['url_len']).tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fd3e617a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>original_url</th>\n",
       "      <th>url_profanity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>members tripod    russiastation</td>\n",
       "      <td>40</td>\n",
       "      <td>42.77.221.155</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://members.tripod.com/russiastation/</td>\n",
       "      <td>0.087409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ddj    cpp 184403822</td>\n",
       "      <td>32</td>\n",
       "      <td>3.211.202.180</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.ddj.com/cpp/184403822</td>\n",
       "      <td>0.046085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>naef-usa</td>\n",
       "      <td>24</td>\n",
       "      <td>24.232.54.41</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.naef-usa.com/</td>\n",
       "      <td>0.279107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ff-b2b</td>\n",
       "      <td>21</td>\n",
       "      <td>147.22.38.45</td>\n",
       "      <td>United States</td>\n",
       "      <td>de</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>720.0</td>\n",
       "      <td>532.8</td>\n",
       "      <td>bad</td>\n",
       "      <td>http://www.ff-b2b.de/</td>\n",
       "      <td>0.045103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>us imdb    title tt0176269</td>\n",
       "      <td>35</td>\n",
       "      <td>205.30.239.85</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>46.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>good</td>\n",
       "      <td>http://us.imdb.com/title/tt0176269/</td>\n",
       "      <td>0.014901</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   url  url_len         ip_add        geo_loc  \\\n",
       "0  members tripod    russiastation           40  42.77.221.155         Taiwan   \n",
       "1              ddj    cpp 184403822          32  3.211.202.180  United States   \n",
       "2                      naef-usa              24   24.232.54.41      Argentina   \n",
       "3                        ff-b2b              21   147.22.38.45  United States   \n",
       "4       us imdb    title tt0176269           35  205.30.239.85  United States   \n",
       "\n",
       "   tld      who_is https  js_len  js_obf_len label  \\\n",
       "0  com    complete   yes    58.0         0.0  good   \n",
       "1  com    complete   yes    52.5         0.0  good   \n",
       "2  com    complete   yes   103.5         0.0  good   \n",
       "3   de  incomplete    no   720.0       532.8   bad   \n",
       "4  com    complete   yes    46.5         0.0  good   \n",
       "\n",
       "                               original_url  url_profanity_score  \n",
       "0  http://members.tripod.com/russiastation/             0.087409  \n",
       "1          http://www.ddj.com/cpp/184403822             0.046085  \n",
       "2                  http://www.naef-usa.com/             0.279107  \n",
       "3                     http://www.ff-b2b.de/             0.045103  \n",
       "4       http://us.imdb.com/title/tt0176269/             0.014901  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from profanity_check import predict, predict_prob\n",
    "df_train['url_profanity_score'] = predict_prob(df_train['url'].astype(str).to_numpy())\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f8607f6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>original_url</th>\n",
       "      <th>url_profanity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>planet-pussy</td>\n",
       "      <td>28</td>\n",
       "      <td>142.196.138.247</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>395.1</td>\n",
       "      <td>217.305</td>\n",
       "      <td>bad</td>\n",
       "      <td>http://www.planet-pussy.com/</td>\n",
       "      <td>0.998407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2123</th>\n",
       "      <td>sexo-gratis anal-hardcore-sex-pics</td>\n",
       "      <td>50</td>\n",
       "      <td>34.116.26.105</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>no</td>\n",
       "      <td>336.6</td>\n",
       "      <td>0.000</td>\n",
       "      <td>bad</td>\n",
       "      <td>http://www.sexo-gratis.anal-hardcore-sex-pics....</td>\n",
       "      <td>0.827001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>rotten    library bio misc dick-wolf</td>\n",
       "      <td>49</td>\n",
       "      <td>122.85.113.65</td>\n",
       "      <td>China</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.000</td>\n",
       "      <td>good</td>\n",
       "      <td>http://www.rotten.com/library/bio/misc/dick-wolf/</td>\n",
       "      <td>0.841259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3431</th>\n",
       "      <td>xxxsex anal-hardcore-sex-pics</td>\n",
       "      <td>45</td>\n",
       "      <td>78.183.245.58</td>\n",
       "      <td>Turkey</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>499.5</td>\n",
       "      <td>264.735</td>\n",
       "      <td>bad</td>\n",
       "      <td>http://www.xxxsex.anal-hardcore-sex-pics.com/</td>\n",
       "      <td>0.827001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4757</th>\n",
       "      <td>free-nude-pussy-pictures    eating-pussy</td>\n",
       "      <td>53</td>\n",
       "      <td>42.76.71.57</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>com</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>371.7</td>\n",
       "      <td>230.454</td>\n",
       "      <td>bad</td>\n",
       "      <td>http://www.free-nude-pussy-pictures.com/eating...</td>\n",
       "      <td>0.998809</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url  url_len  \\\n",
       "1619                             planet-pussy              28   \n",
       "2123       sexo-gratis anal-hardcore-sex-pics              50   \n",
       "2591        rotten    library bio misc dick-wolf           49   \n",
       "3431            xxxsex anal-hardcore-sex-pics              45   \n",
       "4757    free-nude-pussy-pictures    eating-pussy           53   \n",
       "\n",
       "               ip_add        geo_loc  tld      who_is https  js_len  \\\n",
       "1619  142.196.138.247  United States  com  incomplete    no   395.1   \n",
       "2123    34.116.26.105  United States  com    complete    no   336.6   \n",
       "2591    122.85.113.65          China  com    complete   yes   142.5   \n",
       "3431    78.183.245.58         Turkey  com  incomplete    no   499.5   \n",
       "4757      42.76.71.57         Taiwan  com  incomplete    no   371.7   \n",
       "\n",
       "      js_obf_len label                                       original_url  \\\n",
       "1619     217.305   bad                       http://www.planet-pussy.com/   \n",
       "2123       0.000   bad  http://www.sexo-gratis.anal-hardcore-sex-pics....   \n",
       "2591       0.000  good  http://www.rotten.com/library/bio/misc/dick-wolf/   \n",
       "3431     264.735   bad      http://www.xxxsex.anal-hardcore-sex-pics.com/   \n",
       "4757     230.454   bad  http://www.free-nude-pussy-pictures.com/eating...   \n",
       "\n",
       "      url_profanity_score  \n",
       "1619             0.998407  \n",
       "2123             0.827001  \n",
       "2591             0.841259  \n",
       "3431             0.827001  \n",
       "4757             0.998809  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# See URLs with high profanity score\n",
    "df_train[df_train['url_profanity_score'] > 0.8].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc0bbbe8",
   "metadata": {},
   "source": [
    "### Drop URL column now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2dad50c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url_len', 'ip_add', 'geo_loc', 'tld', 'who_is', 'https', 'js_len',\n",
       "       'js_obf_len', 'label', 'original_url', 'url_profanity_score'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop(['url'], axis=1)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e277327a",
   "metadata": {},
   "source": [
    "#### Convert labels to binary labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6412ec46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['label'].replace(to_replace =\"good\", value = 1, inplace = True)\n",
    "df_train['label'].replace(to_replace =\"bad\", value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3726ebc2",
   "metadata": {},
   "source": [
    "Convert IP addresses to split. Eg 192.168.2.254 -> '192', '168', '2', '254'. \n",
    "Split IP addresses is better than binary or one-hot encoding. See https://hammer.purdue.edu/articles/thesis/Encoding_IP_Address_as_a_Feature_for_Network_Intrusion_Detection/11307287"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "cefce193",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train['ip_split_1'], df_train['ip_split_2'], df_train['ip_split_3'], df_train['ip_split_4'] = '','','',''\n",
    "\n",
    "for index, row in df_train.iterrows():\n",
    "    ip_string = row['ip_add']\n",
    "    ip_split_1 = ip_string.split('.')[0]\n",
    "    ip_split_2 = ip_string.split('.')[1]\n",
    "    ip_split_3 = ip_string.split('.')[2]\n",
    "    ip_split_4 = ip_string.split('.')[3]\n",
    "    \n",
    "    # print(ip_split_1, ip_split_2, ip_split_3, ip_split_4)\n",
    "    df_train.at[index, 'ip_split_1'] = ip_split_1\n",
    "    df_train.at[index, 'ip_split_2'] = ip_split_2\n",
    "    df_train.at[index, 'ip_split_3'] = ip_split_3\n",
    "    df_train.at[index, 'ip_split_4'] = ip_split_4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0e15c477",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_add</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>original_url</th>\n",
       "      <th>url_profanity_score</th>\n",
       "      <th>ip_split_1</th>\n",
       "      <th>ip_split_2</th>\n",
       "      <th>ip_split_3</th>\n",
       "      <th>ip_split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>42.77.221.155</td>\n",
       "      <td>Taiwan</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://members.tripod.com/russiastation/</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>42</td>\n",
       "      <td>77</td>\n",
       "      <td>221</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>3.211.202.180</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.ddj.com/cpp/184403822</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>3</td>\n",
       "      <td>211</td>\n",
       "      <td>202</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>24.232.54.41</td>\n",
       "      <td>Argentina</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.naef-usa.com/</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>24</td>\n",
       "      <td>232</td>\n",
       "      <td>54</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>147.22.38.45</td>\n",
       "      <td>United States</td>\n",
       "      <td>de</td>\n",
       "      <td>incomplete</td>\n",
       "      <td>no</td>\n",
       "      <td>720.0</td>\n",
       "      <td>532.8</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.ff-b2b.de/</td>\n",
       "      <td>0.045103</td>\n",
       "      <td>147</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>205.30.239.85</td>\n",
       "      <td>United States</td>\n",
       "      <td>com</td>\n",
       "      <td>complete</td>\n",
       "      <td>yes</td>\n",
       "      <td>46.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://us.imdb.com/title/tt0176269/</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>205</td>\n",
       "      <td>30</td>\n",
       "      <td>239</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len         ip_add        geo_loc  tld      who_is https  js_len  \\\n",
       "0       40  42.77.221.155         Taiwan  com    complete   yes    58.0   \n",
       "1       32  3.211.202.180  United States  com    complete   yes    52.5   \n",
       "2       24   24.232.54.41      Argentina  com    complete   yes   103.5   \n",
       "3       21   147.22.38.45  United States   de  incomplete    no   720.0   \n",
       "4       35  205.30.239.85  United States  com    complete   yes    46.5   \n",
       "\n",
       "   js_obf_len  label                              original_url  \\\n",
       "0         0.0      1  http://members.tripod.com/russiastation/   \n",
       "1         0.0      1          http://www.ddj.com/cpp/184403822   \n",
       "2         0.0      1                  http://www.naef-usa.com/   \n",
       "3       532.8      0                     http://www.ff-b2b.de/   \n",
       "4         0.0      1       http://us.imdb.com/title/tt0176269/   \n",
       "\n",
       "   url_profanity_score  ip_split_1  ip_split_2  ip_split_3  ip_split_4  \n",
       "0             0.087409          42          77         221         155  \n",
       "1             0.046085           3         211         202         180  \n",
       "2             0.279107          24         232          54          41  \n",
       "3             0.045103         147          22          38          45  \n",
       "4             0.014901         205          30         239          85  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train[[\"ip_split_1\", \"ip_split_2\", \"ip_split_3\", \"ip_split_4\"]] = df_train[[\"ip_split_1\", \"ip_split_2\", \"ip_split_3\", \"ip_split_4\"]].apply(pd.to_numeric)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a02f489",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['url_len', 'geo_loc', 'tld', 'who_is', 'https', 'js_len', 'js_obf_len',\n",
       "       'label', 'original_url', 'url_profanity_score', 'ip_split_1',\n",
       "       'ip_split_2', 'ip_split_3', 'ip_split_4'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train = df_train.drop(['ip_add'], axis=1)\n",
    "df_train.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8822a948",
   "metadata": {},
   "source": [
    "### Clean the rest of the categorical columns: geo_loc,\ttld,\twho_is,\thttps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "de45c4b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert http first as it is binary \n",
    "df_train['https'].replace(to_replace =\"yes\", value = 1, inplace = True)\n",
    "df_train['https'].replace(to_replace =\"no\", value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c2a73776",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert who_is next as it is also binary \n",
    "df_train['who_is'].replace(to_replace =\"complete\", value = 1, inplace = True)\n",
    "df_train['who_is'].replace(to_replace =\"incomplete\", value = 0, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c164cbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use ordinal encoding for the other 2 categorical variables\n",
    "df_train['geo_loc'] = OrdinalEncoder().fit_transform(df_train.geo_loc.values.reshape(-1,1))\n",
    "df_train['tld'] = OrdinalEncoder().fit_transform(df_train.tld.values.reshape(-1,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "67c74b8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save geo encoder\n",
    "import pickle\n",
    "import numpy as np\n",
    "geo_enc = OrdinalEncoder()\n",
    "geo_enc.fit(df_train.geo_loc.values.reshape(-1,1))\n",
    "geo_enc.transform(df_train.geo_loc.values.reshape(-1,1))\n",
    "output = open('rf_geo_loc_encoder.pkl', 'wb')\n",
    "pickle.dump(geo_enc, output)\n",
    "output.close()\n",
    "\n",
    "# Save tld encoder\n",
    "tld_enc = OrdinalEncoder()\n",
    "tld_enc.fit(df_train.tld.values.reshape(-1,1))\n",
    "output = open('rf_tld_encoder.pkl', 'wb')\n",
    "pickle.dump(tld_enc, output)\n",
    "output.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1b54cb20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([0.000e+00, 1.000e+00, 2.000e+00, ..., 1.243e+03, 1.244e+03,\n",
       "        1.245e+03])]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tld_enc.categories_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b212783a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[205.],\n",
       "       [222.],\n",
       "       [  9.],\n",
       "       ...,\n",
       "       [ 45.],\n",
       "       [222.],\n",
       "       [222.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.geo_loc.values.reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b9dd67c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1]\n"
     ]
    }
   ],
   "source": [
    "a = df_train['who_is'].unique()\n",
    "print(sorted(a))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ef1c3e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['geo_loc', 'tld'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_data = pd.get_dummies(df_train[['geo_loc','tld']])\n",
    "one_hot_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "1450db6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>205.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>222.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>222.0</td>\n",
       "      <td>282.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>222.0</td>\n",
       "      <td>195.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   geo_loc    tld\n",
       "0    205.0  195.0\n",
       "1    222.0  195.0\n",
       "2      9.0  195.0\n",
       "3    222.0  282.0\n",
       "4    222.0  195.0"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "259efbde",
   "metadata": {},
   "source": [
    "### Time to train our model with our features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3c134a96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>original_url</th>\n",
       "      <th>url_profanity_score</th>\n",
       "      <th>ip_split_1</th>\n",
       "      <th>ip_split_2</th>\n",
       "      <th>ip_split_3</th>\n",
       "      <th>ip_split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40</td>\n",
       "      <td>205.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>58.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://members.tripod.com/russiastation/</td>\n",
       "      <td>0.087409</td>\n",
       "      <td>42</td>\n",
       "      <td>77</td>\n",
       "      <td>221</td>\n",
       "      <td>155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>222.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>52.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.ddj.com/cpp/184403822</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>3</td>\n",
       "      <td>211</td>\n",
       "      <td>202</td>\n",
       "      <td>180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>9.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>103.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://www.naef-usa.com/</td>\n",
       "      <td>0.279107</td>\n",
       "      <td>24</td>\n",
       "      <td>232</td>\n",
       "      <td>54</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>21</td>\n",
       "      <td>222.0</td>\n",
       "      <td>282.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>532.8</td>\n",
       "      <td>0</td>\n",
       "      <td>http://www.ff-b2b.de/</td>\n",
       "      <td>0.045103</td>\n",
       "      <td>147</td>\n",
       "      <td>22</td>\n",
       "      <td>38</td>\n",
       "      <td>45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35</td>\n",
       "      <td>222.0</td>\n",
       "      <td>195.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>46.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>http://us.imdb.com/title/tt0176269/</td>\n",
       "      <td>0.014901</td>\n",
       "      <td>205</td>\n",
       "      <td>30</td>\n",
       "      <td>239</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  geo_loc    tld  who_is  https  js_len  js_obf_len  label  \\\n",
       "0       40    205.0  195.0       1      1    58.0         0.0      1   \n",
       "1       32    222.0  195.0       1      1    52.5         0.0      1   \n",
       "2       24      9.0  195.0       1      1   103.5         0.0      1   \n",
       "3       21    222.0  282.0       0      0   720.0       532.8      0   \n",
       "4       35    222.0  195.0       1      1    46.5         0.0      1   \n",
       "\n",
       "                               original_url  url_profanity_score  ip_split_1  \\\n",
       "0  http://members.tripod.com/russiastation/             0.087409          42   \n",
       "1          http://www.ddj.com/cpp/184403822             0.046085           3   \n",
       "2                  http://www.naef-usa.com/             0.279107          24   \n",
       "3                     http://www.ff-b2b.de/             0.045103         147   \n",
       "4       http://us.imdb.com/title/tt0176269/             0.014901         205   \n",
       "\n",
       "   ip_split_2  ip_split_3  ip_split_4  \n",
       "0          77         221         155  \n",
       "1         211         202         180  \n",
       "2         232          54          41  \n",
       "3          22          38          45  \n",
       "4          30         239          85  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "47e488af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "url_len                  int64\n",
       "geo_loc                float64\n",
       "tld                    float64\n",
       "who_is                   int64\n",
       "https                    int64\n",
       "js_len                 float64\n",
       "js_obf_len             float64\n",
       "label                    int64\n",
       "original_url            object\n",
       "url_profanity_score    float64\n",
       "ip_split_1               int64\n",
       "ip_split_2               int64\n",
       "ip_split_3               int64\n",
       "ip_split_4               int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "456c09eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note that test set is in the other csv file\n",
    "X_train = df_train[['url_len', 'ip_split_1', 'ip_split_2', 'ip_split_3', 'ip_split_4', \n",
    "             'geo_loc', 'tld', 'who_is', 'js_len', 'js_obf_len', 'https', 'url_profanity_score']]\n",
    "y_train = df_train.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cf0e99",
   "metadata": {},
   "source": [
    "### Load test data and prepare for use to get test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e9a92851",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv('Webpages_Classification_test_data.csv')\n",
    "df_test = df_test.drop(['Unnamed: 0', 'content'], axis=1)\n",
    "df_test['url'] = df_test['url'].map(clean_url)\n",
    "df_test['url_profanity_score'] = predict_prob(df_test['url'].astype(str).to_numpy())\n",
    "df_test = df_test.drop(['url'], axis=1)\n",
    "df_test['label'].replace(to_replace =\"good\", value = 1, inplace = True)\n",
    "df_test['label'].replace(to_replace =\"bad\", value = 0, inplace = True)\n",
    "df_test['ip_split_1'], df_test['ip_split_2'], df_test['ip_split_3'], df_test['ip_split_4'] = '','','',''\n",
    "for index, row in df_test.iterrows():\n",
    "    ip_string = row['ip_add']\n",
    "    ip_split_1 = ip_string.split('.')[0]\n",
    "    ip_split_2 = ip_string.split('.')[1]\n",
    "    ip_split_3 = ip_string.split('.')[2]\n",
    "    ip_split_4 = ip_string.split('.')[3]\n",
    "    df_test.at[index, 'ip_split_1'] = ip_split_1\n",
    "    df_test.at[index, 'ip_split_2'] = ip_split_2\n",
    "    df_test.at[index, 'ip_split_3'] = ip_split_3\n",
    "    df_test.at[index, 'ip_split_4'] = ip_split_4\n",
    "df_test['https'].replace(to_replace =\"yes\", value = 1, inplace = True)\n",
    "df_test['https'].replace(to_replace =\"no\", value = 0, inplace = True)\n",
    "df_test['who_is'].replace(to_replace =\"complete\", value = 1, inplace = True)\n",
    "df_test['who_is'].replace(to_replace =\"incomplete\", value = 0, inplace = True)\n",
    "df_test['geo_loc'] = OrdinalEncoder().fit_transform(df_test.geo_loc.values.reshape(-1,1))\n",
    "df_test['tld'] = OrdinalEncoder().fit_transform(df_test.tld.values.reshape(-1,1))\n",
    "df_test = df_test.drop(['ip_add'], axis=1)\n",
    "df_test[[\"ip_split_1\", \"ip_split_2\", \"ip_split_3\", \"ip_split_4\"]] = df_test[[\"ip_split_1\", \"ip_split_2\", \"ip_split_3\", \"ip_split_4\"]].apply(pd.to_numeric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8b80b2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract test set from df_test\n",
    "X_test = df_test[['url_len', 'ip_split_1', 'ip_split_2', 'ip_split_3', 'ip_split_4', \n",
    "             'geo_loc', 'tld', 'who_is', 'js_len', 'js_obf_len', 'https', 'url_profanity_score']]\n",
    "y_test = df_test.label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82c692f4",
   "metadata": {},
   "source": [
    "### Train decision tree model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "addb7740",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'splitter': ['best', 'random']}])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train model\n",
    "# Decision Tree\n",
    "\n",
    "param_grid=[{\"criterion\":[\"gini\", \"entropy\"],\n",
    "             \"splitter\":[\"best\", \"random\"]}]\n",
    "decision_tree_grid=GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),param_grid=param_grid,cv=5)\n",
    "decision_tree_grid.fit(X_train,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "423a5f10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(random_state=42),\n",
       "             param_grid=[{'criterion': ['entropy'], 'splitter': ['best']}])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid=[{\"criterion\":[\"entropy\"],\n",
    "             \"splitter\":[\"best\"]}]\n",
    "decision_tree_grid=GridSearchCV(estimator=DecisionTreeClassifier(random_state=42),param_grid=param_grid,cv=5)\n",
    "decision_tree_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c293e7da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree best params:  {'criterion': 'entropy', 'splitter': 'best'}\n"
     ]
    }
   ],
   "source": [
    "print('Decision tree best params: ', decision_tree_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "20af1252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision tree test accuracy:  0.998488674730752\n"
     ]
    }
   ],
   "source": [
    "print('Decision tree test accuracy: ', decision_tree_grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9af3b5b1",
   "metadata": {},
   "source": [
    "## Train Gradient Boosting Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57de6ed3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:12:16] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:12:19] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:17:06] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:17:07] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:22:08] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:22:10] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:31:46] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:31:47] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:37:21] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:37:22] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[22:55:54] WARNING: ..\\src\\learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "[22:56:03] WARNING: ..\\src\\learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      " All results:\n",
      "{'mean_fit_time': array([521.06897645]), 'std_fit_time': array([309.49768514]), 'mean_score_time': array([1.94962845]), 'std_score_time': array([2.28822253]), 'param_gamma': masked_array(data=[0.5],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_max_depth': masked_array(data=[5],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_child_weight': masked_array(data=[1],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_subsample': masked_array(data=[1.0],\n",
      "             mask=[False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0}], 'split0_test_score': array([0.99894167]), 'split1_test_score': array([0.999025]), 'split2_test_score': array([0.9990375]), 'split3_test_score': array([0.9990625]), 'split4_test_score': array([0.998975]), 'mean_test_score': array([0.99900833]), 'std_test_score': array([4.38589912e-05]), 'rank_test_score': array([1])}\n",
      "\n",
      " Best estimator:\n",
      "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0.5, gpu_id=-1,\n",
      "              importance_type='gain', interaction_constraints='',\n",
      "              learning_rate=0.02, max_delta_step=0, max_depth=5,\n",
      "              min_child_weight=1, missing=nan, monotone_constraints='()',\n",
      "              n_estimators=600, n_jobs=1, nthread=1, num_parallel_tree=1,\n",
      "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=1,\n",
      "              silent=True, subsample=1.0, tree_method='exact',\n",
      "              validate_parameters=1, verbosity=None)\n",
      "\n",
      " Best hyperparameters:\n",
      "{'gamma': 0.5, 'max_depth': 5, 'min_child_weight': 1, 'subsample': 1.0}\n",
      "XGB test accuracy:  0.9990771798173148\n"
     ]
    }
   ],
   "source": [
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# XBB grid search\n",
    "xgb_model = XGBClassifier(learning_rate=0.02, n_estimators=600, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)\n",
    "params = {\n",
    "        'min_child_weight': [1],\n",
    "        'gamma': [0.5],\n",
    "        'subsample': [1.0],\n",
    "        'max_depth': [5]\n",
    "        }\n",
    "xgb_grid = GridSearchCV(estimator=xgb_model, param_grid=params, cv=5)\n",
    "xgb_grid.fit(X_train,y_train)\n",
    "\n",
    "print('\\n All results:')\n",
    "print(xgb_grid.cv_results_)\n",
    "print('\\n Best estimator:')\n",
    "print(xgb_grid.best_estimator_)\n",
    "print('\\n Best hyperparameters:')\n",
    "print(xgb_grid.best_params_)\n",
    "\n",
    "# Get xgb test score\n",
    "print('XGB test accuracy: ', xgb_grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f8464e33",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:615: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 598, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1306, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 443, in _check_solver\n",
      "    raise ValueError(\"Solver %s supports only 'l2' or 'none' penalties, \"\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(\"Estimator fit failed. The score on this train-test\"\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\model_selection\\_search.py:922: UserWarning: One or more of the test scores are non-finite: [       nan 0.9975325         nan 0.9976375         nan 0.99765583\n",
      "        nan 0.99766833        nan 0.9976775         nan 0.99769333\n",
      "        nan 0.9976925 ]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tuned hpyerparameters :(best parameters)  {'C': 100.0, 'penalty': 'l2'}\n",
      "accuracy : 0.9976933333333333\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\hatzi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression grid search\n",
    "import numpy as np\n",
    "grid={\"C\":np.logspace(-3,3,7), \"penalty\":[\"l1\",\"l2\"]}# l1 lasso l2 ridge\n",
    "logreg=LogisticRegression()\n",
    "logreg_cv=GridSearchCV(logreg,grid,cv=10)\n",
    "logreg_cv.fit(X_train,y_train)\n",
    "\n",
    "print(\"tuned hpyerparameters :(best parameters) \",logreg_cv.best_params_)\n",
    "print(\"accuracy :\",logreg_cv.best_score_)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bb79fe",
   "metadata": {},
   "source": [
    "## Train logistic regression model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "40f9cb2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic regression test accuracy:  0.9977537341062183\n"
     ]
    }
   ],
   "source": [
    "# Logistic regression test score\n",
    "print('Logistic regression test accuracy: ', logreg_cv.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf223086",
   "metadata": {},
   "source": [
    "### Train random forest model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "9198103a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid=[{'criterion': ['gini', 'entropy'],\n",
       "                          'n_estimators': [10, 20, 30, 40, 50, 60, 70, 80, 90,\n",
       "                                           100, 110]}])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "param_grid=[{\"n_estimators\":[x for x in range(10, 120, 10)],\n",
    "             \"criterion\":[\"gini\", \"entropy\"]}]\n",
    "forest_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42),param_grid=param_grid,cv=5)\n",
    "forest_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b65249dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest best params:  {'criterion': 'entropy', 'n_estimators': 110}\n"
     ]
    }
   ],
   "source": [
    "print('Random forest best params: ', forest_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9e305230",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy:  0.9990467875358491\n"
     ]
    }
   ],
   "source": [
    "print('Random forest accuracy: ', forest_grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fbc3b264",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=RandomForestClassifier(random_state=42),\n",
       "             param_grid=[{'criterion': ['entropy'], 'n_estimators': [110]}])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid=[{\"n_estimators\":[110],\n",
    "             \"criterion\":[\"entropy\"]}]\n",
    "forest_grid = GridSearchCV(estimator=RandomForestClassifier(random_state=42),param_grid=param_grid,cv=5)\n",
    "forest_grid.fit(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "0cbf9937",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random forest accuracy:  0.9990467875358491\n"
     ]
    }
   ],
   "source": [
    "print('Random forest accuracy: ', forest_grid.score(X_test,y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bcf21f",
   "metadata": {},
   "source": [
    "### Can conclude that random forest is the best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "bf13cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test prediction on a malicious label ie label == 0\n",
    "test_label_0 = df_test[df_test['label'] == 0]\n",
    "test_label_0_pred = df_test.label\n",
    "test_label_0 = test_label_0[['url_len', 'ip_split_1', 'ip_split_2', 'ip_split_3', 'ip_split_4', \n",
    "             'geo_loc', 'tld', 'who_is', 'js_len', 'js_obf_len', 'https', 'url_profanity_score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "83d26c7e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest_grid.predict(test_label_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "dd4762a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>https</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>label</th>\n",
       "      <th>url_profanity_score</th>\n",
       "      <th>ip_split_1</th>\n",
       "      <th>ip_split_2</th>\n",
       "      <th>ip_split_3</th>\n",
       "      <th>ip_split_4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>29</td>\n",
       "      <td>206.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>356.4</td>\n",
       "      <td>178.200</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>75</td>\n",
       "      <td>165</td>\n",
       "      <td>190</td>\n",
       "      <td>102</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>266</th>\n",
       "      <td>28</td>\n",
       "      <td>180.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>808.2</td>\n",
       "      <td>363.690</td>\n",
       "      <td>0</td>\n",
       "      <td>0.090648</td>\n",
       "      <td>61</td>\n",
       "      <td>83</td>\n",
       "      <td>239</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>29</td>\n",
       "      <td>95.0</td>\n",
       "      <td>201.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>779.4</td>\n",
       "      <td>319.554</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>87</td>\n",
       "      <td>43</td>\n",
       "      <td>230</td>\n",
       "      <td>193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>400</th>\n",
       "      <td>22</td>\n",
       "      <td>101.0</td>\n",
       "      <td>412.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>365.4</td>\n",
       "      <td>193.662</td>\n",
       "      <td>0</td>\n",
       "      <td>0.051925</td>\n",
       "      <td>163</td>\n",
       "      <td>216</td>\n",
       "      <td>178</td>\n",
       "      <td>149</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>29</td>\n",
       "      <td>206.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>392.4</td>\n",
       "      <td>200.124</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046085</td>\n",
       "      <td>75</td>\n",
       "      <td>195</td>\n",
       "      <td>91</td>\n",
       "      <td>191</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     url_len  geo_loc    tld  who_is  https  js_len  js_obf_len  label  \\\n",
       "93        29    206.0  136.0       0      0   356.4     178.200      0   \n",
       "266       28    180.0  136.0       0      0   808.2     363.690      0   \n",
       "326       29     95.0  201.0       0      0   779.4     319.554      0   \n",
       "400       22    101.0  412.0       0      0   365.4     193.662      0   \n",
       "422       29    206.0  136.0       0      0   392.4     200.124      0   \n",
       "\n",
       "     url_profanity_score  ip_split_1  ip_split_2  ip_split_3  ip_split_4  \n",
       "93              0.046085          75         165         190         102  \n",
       "266             0.090648          61          83         239          62  \n",
       "326             0.046085          87          43         230         193  \n",
       "400             0.051925         163         216         178         149  \n",
       "422             0.046085          75         195          91         191  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test[df_test['label'] == 0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "06a330ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['random_forest.pkl']"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Save model to disk\n",
    "import joblib\n",
    "\n",
    "#save your model or results\n",
    "joblib.dump(forest_grid, 'random_forest.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d9cd8d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load your model for further usage\n",
    "import joblib\n",
    "loaded_model = joblib.load(\"random_forest.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6b9e1952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.model_selection._search.GridSearchCV"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(loaded_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "35dedf99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sklearn.ensemble._forest.RandomForestClassifier"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get feature importance of random forest model\n",
    "rf_model = loaded_model.best_estimator_\n",
    "type(rf_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a2085b50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print random forest feature importance\n",
    "import matplotlib.pyplot as plt\n",
    "columns = X_train.columns\n",
    "\n",
    "feat_importances = pd.Series(rf_model.feature_importances_, index=columns)\n",
    "feat_importances.nlargest(10).plot(kind='barh')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "74d32d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total rows: 1561934\n",
      "Label 0 percentage: 0.022609790170391324 Label 0 counts: 35315\n",
      "Label 1 percentage: 0.9773902098296087 Label 1 counts: 1526619\n"
     ]
    }
   ],
   "source": [
    "# Check for class imbalance\n",
    "\n",
    "total_rows = len(df_test) + len(df_train)\n",
    "total_0 = len(df_test[df_test['label'] == 0]) + len(df_train[df_train['label'] == 0])\n",
    "total_1 = len(df_test[df_test['label'] == 1]) + len(df_train[df_train['label'] == 1])\n",
    "\n",
    "print('Total rows:', total_rows)\n",
    "print('Label 0 percentage:', total_0 / total_rows, 'Label 0 counts:', total_0)\n",
    "print('Label 1 percentage:', total_1 / total_rows, 'Label 1 counts:', total_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b443418",
   "metadata": {},
   "source": [
    "### Do a test prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "e50455a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "a6d1889d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_split_1</th>\n",
       "      <th>ip_split_2</th>\n",
       "      <th>ip_split_3</th>\n",
       "      <th>ip_split_4</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>https</th>\n",
       "      <th>url_profanity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>175</td>\n",
       "      <td>67</td>\n",
       "      <td>214</td>\n",
       "      <td>68</td>\n",
       "      <td>41.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>32</td>\n",
       "      <td>188</td>\n",
       "      <td>120</td>\n",
       "      <td>171</td>\n",
       "      <td>121</td>\n",
       "      <td>187.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>0</td>\n",
       "      <td>187.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27</td>\n",
       "      <td>193</td>\n",
       "      <td>51</td>\n",
       "      <td>170</td>\n",
       "      <td>1</td>\n",
       "      <td>67.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.046085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>13</td>\n",
       "      <td>237</td>\n",
       "      <td>35</td>\n",
       "      <td>44</td>\n",
       "      <td>11.0</td>\n",
       "      <td>276.0</td>\n",
       "      <td>1</td>\n",
       "      <td>152.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>40</td>\n",
       "      <td>220</td>\n",
       "      <td>193</td>\n",
       "      <td>62</td>\n",
       "      <td>89</td>\n",
       "      <td>41.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>150.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.025919</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  ip_split_1  ip_split_2  ip_split_3  ip_split_4  geo_loc    tld  \\\n",
       "0       36         175          67         214          68     41.0  136.0   \n",
       "1       32         188         120         171         121    187.0  136.0   \n",
       "2       27         193          51         170           1     67.0  136.0   \n",
       "3       56          13         237          35          44     11.0  276.0   \n",
       "4       40         220         193          62          89     41.0  136.0   \n",
       "\n",
       "   who_is  js_len  js_obf_len  https  url_profanity_score  \n",
       "0       1    38.5         0.0      1             0.046085  \n",
       "1       0   187.0         0.0      1             0.046085  \n",
       "2       1    31.0         0.0      1             0.046085  \n",
       "3       1   152.0         0.0      1             0.077642  \n",
       "4       1   150.0         0.0      1             0.025919  "
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "a5226cc0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "71b91902",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url_len</th>\n",
       "      <th>ip_split_1</th>\n",
       "      <th>ip_split_2</th>\n",
       "      <th>ip_split_3</th>\n",
       "      <th>ip_split_4</th>\n",
       "      <th>geo_loc</th>\n",
       "      <th>tld</th>\n",
       "      <th>who_is</th>\n",
       "      <th>js_len</th>\n",
       "      <th>js_obf_len</th>\n",
       "      <th>https</th>\n",
       "      <th>url_profanity_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>36</td>\n",
       "      <td>175</td>\n",
       "      <td>32</td>\n",
       "      <td>214</td>\n",
       "      <td>68</td>\n",
       "      <td>41.0</td>\n",
       "      <td>136.0</td>\n",
       "      <td>1</td>\n",
       "      <td>38.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.987</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   url_len  ip_split_1  ip_split_2  ip_split_3  ip_split_4  geo_loc    tld  \\\n",
       "0       36         175          32         214          68     41.0  136.0   \n",
       "\n",
       "   who_is  js_len  js_obf_len  https  url_profanity_score  \n",
       "0       1    38.5         0.0      1                0.987  "
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "values = {\n",
    "    'url_len': [36], 'ip_split_1': [175], 'ip_split_2': [32], 'ip_split_3': [214], 'ip_split_4': [68], \n",
    "    'geo_loc': [41.0], 'tld': [136.0], 'who_is': [1], 'js_len': [38.5], 'js_obf_len': [0.0], \n",
    "    'https': [1], 'url_profanity_score': [0.987]\n",
    "}\n",
    "test_data = pd.DataFrame.from_dict(values)\n",
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "7bfded94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1], dtype=int64)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9f7e152f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.02727273, 0.97272727]])"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_model.predict_proba(test_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
